# -*- coding: utf-8 -*-
"""Pneumonia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c3pWyXgW-gO4IVfFnctpPGNbfTAi2inI
"""

from google.colab import drive
drive.mount('/content/drive')

#1. Import packages
import pandas as pd
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os, datetime

#2. Data loading
csv_train_path = os.path.join("/content/drive/MyDrive/cases_malaysia_test.csv")
csv_test_path = os.path.join("/content/drive/MyDrive/cases_malaysia_train.csv")

df_train = pd.read_csv(csv_train_path)
df_test = pd.read_csv(csv_test_path)

df_train.head()

df_train.tail()

#3. Data inspection
#(A) Check for info
print("------------TRAIN DATA INFO------------")
df_train.info()
print("------------TEST DATA INFO------------")
df_test.info()

#(B)Check for NA values
df_train.isna().sum()

df_test.isna().sum()

import pandas as pd
from sklearn.impute import SimpleImputer

# Fill missing values with the mean of the column
imputer = SimpleImputer(strategy='mean')
df_train['cases_new'] = imputer.fit_transform(df_train[['cases_new']])

#5. Feature selection
# We are selecting "cases_new" as the feature
df_train_open = df_train["cases_new"]
df_test_open = df_train["cases_new"]

#6. Data preprocessing
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
df_train_open_scaled = mms.fit_transform(np.expand_dims(df_train_open, axis=-1))
df_test_open_scaled = mms.fit_transform(np.expand_dims(df_train_open, axis=-1))

#7. Data windowing
window_size = 30
X_train = []
y_train = []

for i in range(window_size,len(df_train_open_scaled)):
    X_train.append(df_train_open_scaled[i-window_size:i])
    y_train.append(df_train_open_scaled[i])

X_train = np.array(X_train)
y_train = np.array(y_train)

df_open_stacked = np.concatenate((df_train_open_scaled, df_test_open_scaled))
length_days = window_size + len(df_test_open_scaled)
data_test = df_open_stacked[-length_days:]

X_test = []
y_test =[]

for i in range(window_size,len(data_test)):
    X_test.append(data_test[i-window_size:i])
    y_test.append(data_test[i])

X_test = np.array(X_train)
y_test = np.array(y_train)

#8. Model development

from tensorflow.keras import Sequential,Input
from tensorflow.keras.layers import LSTM,Dropout,Dense
from tensorflow.keras.utils import plot_model

input_shape = np.shape(X_train)[1:]

model = Sequential()
model.add(Input(shape=(input_shape)))
model.add(LSTM(128,return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(128,return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(128))
model.add(Dropout(0.3))
model.add(Dense(1,activation='relu'))

model.summary()
plot_model(model,show_shapes=True,show_layer_names=True)

#9. Model compilation
model.compile(optimizer='adam',loss='mse',metrics=['mae', 'mape'])

#10. Model training
history = model.fit(X_test,y_test,epochs=100,validation_data=(X_test,y_test))

#6. Model evaluation
print(history.history.keys())

#Plot the evaluation graph
plt.figure()
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.legend(['Train MAE','Test MAE'])
plt.show()

#Deploy the model
y_pred = model.predict(X_test)

#Perform inverse transform
actual_cases= mms.inverse_transform(y_test)
predicted_cases= mms.inverse_transform(y_pred)

#Plot actual vs predicted
plt.figure()
plt.plot(actual_cases,color='red')
plt.plot(predicted_cases,color='blue')
plt.xlabel("Time")
plt.ylabel("Number of Cases")
plt.legend(['Actual Cases','Predicted Cases'])